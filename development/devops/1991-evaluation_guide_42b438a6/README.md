# Evaluation Guide

| Property | Value |
|----------|-------|
| **Name** | Evaluation Guide |
| **Repository** | [cisco-ai-defense/skill-scanner](https://raw.githubusercontent.com/cisco-ai-defense/skill-scanner/main/evals/EVALUATION_GUIDE.md) (‚≠ê 324) |
| **Original Path** | `evals/EVALUATION_GUIDE.md` |
| **Category** | development |
| **Subcategory** | devops |
| **Tags** | development |
| **Created** | 2026-01-29 |
| **Updated** | 2026-01-29 |
| **File Hash** | `42b438a6a7df2e20...` |

## Description

The evaluation framework (evals/eval_runner.py) tests analyzer accuracy by comparing actual scan results against expected ground truth defined in _expected.json files.

**Tags:** `development`

---

*This skill is maintained by [SkillFlow](https://github.com/tools-only/SkillFlow)*
*Source: [cisco-ai-defense/skill-scanner](https://raw.githubusercontent.com/cisco-ai-defense/skill-scanner/main/evals/EVALUATION_GUIDE.md)*
