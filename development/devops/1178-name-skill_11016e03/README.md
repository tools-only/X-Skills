# Skill

| Property | Value |
|----------|-------|
| **Name** | Skill |
| **Repository** | [davila7/claude-code-templates](https://raw.githubusercontent.com/davila7/claude-code-templates/main/cli-tool/components/skills/ai-research/optimization-gguf/SKILL.md) (ðŸ”¥ 19.4k) |
| **Original Path** | `cli-tool/components/skills/ai-research/optimization-gguf/SKILL.md` |
| **Category** | development |
| **Subcategory** | devops |
| **Tags** | GGUF, Quantization, llama.cpp, CPU Inference, Apple Silicon |
| **Created** | 2026-01-08 |
| **Updated** | 2026-01-08 |
| **File Hash** | `11016e03b2b53c9a...` |

## Description

The GGUF (GPTGenerated Unified Format) is the standard file format for llama.cpp, enabling efficient inference on CPUs, Apple Silicon, and GPUs with flexible quantization options.

**Tags:** `GGUF` `Quantization` `llama.cpp` `CPU Inference` `Apple Silicon`

---

*This skill is maintained by [SkillFlow](https://github.com/tools-only/SkillFlow)*
*Source: [davila7/claude-code-templates](https://raw.githubusercontent.com/davila7/claude-code-templates/main/cli-tool/components/skills/ai-research/optimization-gguf/SKILL.md)*
