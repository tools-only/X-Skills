---
argument-hint: [--report] [--issue] [--scope <path>]
description: Run full codebase review using automatic-code-review rules
allowed-tools: Glob, Read, Write, Bash, Task
---

# Full Codebase Review

Review the entire codebase against `.claude/automatic-code-review/rules.md` - the same rules used for automatic code review on modified files, but applied to everything.

## Arguments

- `--report`: Save findings to `docs/reviews/YYYY-MM-DD-full-review.md`
- `--issue`: Create GitHub issue with findings summary
- `--scope <path>`: Limit to specific path (default: entire codebase)

Parse these from `$ARGUMENTS`.

## Procedure

### Step 1: Parse Arguments

```
ARGUMENTS: $ARGUMENTS
```

Extract:
- `generate_report`: true if `--report` present
- `create_issue`: true if `--issue` present
- `scope_path`: value after `--scope` or default to project root

### Step 2: Discover Files

Use Glob to find all TypeScript files (production AND test files):

```
Pattern: **/*.{ts,tsx}
```

The Glob tool respects `.gitignore`, so `node_modules/`, `dist/`, etc. are automatically excluded.

If `scope_path` is set, use that as the base path for the glob.

**Categorize files:**
- Test files: any file matching `*.spec.ts`, `*.spec.tsx`, `*.test.ts`, `*.test.tsx`
- Production files: all other `.ts`/`.tsx` files

**Store the complete file lists** - these will be included in the report appendix.

Report:
```
Found X files to review:
- Production files: Y
- Test files: Z
```

### Step 3: Chunk Files

Split file list into chunks of ~30 files each.

Chunking logic:
- If total files <= 30: single chunk
- Otherwise: split evenly into chunks of ~30 files

Report: "Split into X chunks of ~Y files each"

### Step 4: Review Each Chunk

For each chunk, spawn the `automatic-code-reviewer` subagent:

```
Use Task tool with:
- subagent_type: "automatic-code-reviewer"
- prompt: "Review these files: [file1, file2, ...]"
```

**Important:** The automatic-code-reviewer will:
1. Read `.claude/settings.json` to find the rules file
2. Read the rules file (`.claude/automatic-code-review/rules.md`)
3. Review each file against ALL rules
4. Return findings in structured format

Collect ALL findings from each chunk.

### Step 5: Aggregate Results

Combine findings from all chunks into categories:

1. **Architecture/Modularity Violations**
2. **Coding Standards Violations**
3. **Testing Standards Violations**
4. **Dangerous Fallback Values**
5. **Anti-Pattern Violations**
6. **Duplicated Code**
7. **Other Findings** (anything that doesn't fit the above)
8. **Suggested Updates**

Deduplicate similar findings.
Sort by severity (Critical > High > Medium > Low).

### Step 6: Display Summary

Always display a summary to the user:

```
## Full Codebase Review Complete

**Files reviewed:**
- Production files: X
- Test files: Y
- Total: Z

**Chunks processed:** N
**Total violations found:** V

### By Category:
- Architecture/Modularity: N
- Coding Standards: N
- Testing Standards: N
- Dangerous Fallbacks: N
- Anti-Patterns: N
- Duplicated Code: N
- Other: N

### Top Issues:
1. [Most critical finding]
2. [Second most critical]
3. [Third most critical]
```

### Step 7: Generate Report (if --report)

If `generate_report` is true:

1. Create directory: `docs/reviews/` (if doesn't exist)
2. Write report to: `docs/reviews/YYYY-MM-DD-full-review.md`

Report format:

```markdown
# Full Codebase Review - YYYY-MM-DD

## Summary

- **Production files reviewed:** X
- **Test files reviewed:** Y
- **Total files reviewed:** Z
- **Chunks processed:** N
- **Total violations:** V
- **Review rules:** .claude/automatic-code-review/rules.md

## Architecture/Modularity Violations

[List all findings with file:line, issue, suggested fix]

## Coding Standards Violations

[List all findings]

## Testing Standards Violations

[List all findings]

## Dangerous Fallback Values

[List all findings]

## Anti-Pattern Violations

[List all findings]

## Duplicated Code

[List all findings]

## Other Findings

[Anything that doesn't fit the categories above]

## Suggested Updates to Conventions

Based on patterns found in this review:

1. [Suggestion for updating docs/conventions/]
2. [Another suggestion]

---

## Appendix: Files Reviewed

### Production Files (X)

<details>
<summary>Click to expand full list</summary>

- path/to/file1.ts
- path/to/file2.ts
...
</details>

### Test Files (Y)

<details>
<summary>Click to expand full list</summary>

- path/to/file1.spec.ts
- path/to/file2.test.ts
...
</details>

---

*Generated by full-codebase-review plugin*
```

Report: "Report saved to docs/reviews/YYYY-MM-DD-full-review.md"

### Step 8: Create GitHub Issue (if --issue)

If `create_issue` is true:

Use Bash to create issue via `gh`:

```bash
gh issue create \
  --title "Full Codebase Review - YYYY-MM-DD" \
  --body "$(cat <<'EOF'
## Summary

- Files reviewed: X
- Total violations: Z

## Action Required

### Critical (fix immediately)
- [ ] [Critical finding 1]
- [ ] [Critical finding 2]

### High Priority
- [ ] [High priority finding 1]
- [ ] [High priority finding 2]

## Full Report

See: docs/reviews/YYYY-MM-DD-full-review.md (if --report was used)

---
*Generated by full-codebase-review plugin*
EOF
)" \
  --label "tech-debt" \
  --label "code-review"
```

Report the issue URL.

## Error Handling

- If no files found: Report "No TypeScript files found" and exit
- If rules file not found: Warn but continue with basic review (automatic-code-reviewer handles this)
- If chunk review fails: Log error, continue with remaining chunks
- If `gh` not installed: Warn and skip issue creation

## Notes

- This reuses the existing `automatic-code-reviewer` agent from the `automatic-code-review` plugin
- The same rules.md file is used, ensuring consistency between session reviews and full reviews
- Large codebases may take significant time - consider using `--scope` to limit
