# Relu Extraction Theory

| Property | Value |
|----------|-------|
| **Name** | Relu Extraction Theory |
| **Repository** | [letta-ai/skills](https://raw.githubusercontent.com/letta-ai/skills/main/letta/benchmarks/trajectory-only/model-extraction-relu-logits/references/relu_extraction_theory.md) (‚≠ê 44) |
| **Original Path** | `letta/benchmarks/trajectory-only/model-extraction-relu-logits/references/relu_extraction_theory.md` |
| **Category** | development |
| **Subcategory** | coding |
| **Tags** | development |
| **Created** | 2025-12-19 |
| **Updated** | 2025-12-19 |
| **File Hash** | `c4ba2be97b562eea...` |

## Description

Consider a twolayer ReLU network:

**Tags:** `development`

---

*This skill is maintained by [SkillFlow](https://github.com/tools-only/SkillFlow)*
*Source: [letta-ai/skills](https://raw.githubusercontent.com/letta-ai/skills/main/letta/benchmarks/trajectory-only/model-extraction-relu-logits/references/relu_extraction_theory.md)*
