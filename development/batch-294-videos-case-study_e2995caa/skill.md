# ğŸ“Š Case Study: Big vs Small Batch Comparison

> Real production data from Washin Village animal video analysis

## ğŸ”¥ The Biggest Discovery: Bigger is Faster AND Cheaper!

We ran 3 batches and compared everything:

| Batch | Requests | Sent (JST) | Done (JST) | Total Time | Per Request |
|-------|----------|------------|------------|------------|-------------|
| ğŸ˜ **Large** | 294 | 10:22 | 12:35 | 133 min | **0.45 min** |
| ğŸ° Small | 10 | 11:50 | 13:28 | 98 min | 9.84 min |
| ğŸ Test | 3 | 01:20 | 02:23 | 62 min | 20.77 min |

### Wait... the Large batch finished FIRST?!

Yes! Even though:
- Large batch was sent at 10:22
- Small batch was sent at 11:50 (1.5 hours later)
- **Large batch still finished 53 minutes before small batch!**

**This means: Anthropic does NOT process in order (FIFO). Bigger batches get priority!**

---

## ğŸ§  Why Does This Happen? (Simple Explanation)

Think of Anthropic's GPU like an oven:

```
ğŸ”¥ Oven preheating = 15 minutes (fixed cost, always pay this)

Large batch (294 items):
  Preheat 15 min â†’ Bake all 294 â†’ Average = 0.45 min each âœ…

Small batch (10 items):
  Preheat 15 min â†’ Bake only 10 â†’ Average = 9.84 min each âŒ

The more you bake, the cheaper per item!
```

---

## ğŸ“Š Token Usage Comparison

| Batch | Input | Output | Cache Write | Cache Read | Avg Output |
|-------|-------|--------|-------------|------------|------------|
| ğŸ˜ Large | 365,624 | 611,412 | 106,920 | 416,988 | 2,080/req |
| ğŸ° Small | 12,988 | 2,576 | 0 | 0 | 258/req |
| ğŸ Test | 3,612 | 6,016 | 1,782 | 3,564 | 2,005/req |

### Why does Large batch have Cache but Small doesn't?

- **Large + Test batch**: Same system prompt (GAIA Stage 2) â†’ Cache works!
- **Small batch**: Different prompt (random test) â†’ No cache

**Lesson: Put same-type requests together to share cache!**

---

## ğŸ’° Cost Analysis

### Large Batch (294 videos)

| Item | Value |
|------|-------|
| Total Tokens | 1,500,944 |
| Original Cost | $11.04 |
| **Batch Cost** | **$5.52** |
| **Savings** | **50%** âœ… |

### The "22x Efficiency Gap"

| Batch | Time per Request | Relative Cost |
|-------|------------------|---------------|
| ğŸ˜ Large (294) | 0.45 min | **1x** (cheapest) |
| ğŸ° Small (10) | 9.84 min | **22x** more expensive! |
| ğŸ Test (3) | 20.77 min | **46x** more expensive! |

---

## ğŸ’¡ What Official Docs Don't Tell You

| Topic | Official Says | We Discovered |
|-------|---------------|---------------|
| **Processing Order** | "Within 24 hours" | Big batches get priority (not FIFO!) |
| **Batch Size Effect** | Nothing | 22x efficiency difference! |
| **Cache for Images** | "90% savings" | Only 14% for images (85% is image data, can't cache) |
| **Scale Effect** | Nothing | More requests = cheaper per request |

### Why Image Cache Only Saves 14%?

```
Your request content:
â”œâ”€â”€ System Prompt (text): 15% â†’ âœ… Can cache (90% off)
â””â”€â”€ Image Data: 85% â†’ âŒ Cannot cache

Actual savings: 15% Ã— 90% = ~14%
```

---

## âœ… Best Practices (Based on Real Data)

### DO âœ…

| Action | Why |
|--------|-----|
| Batch 100+ requests together | 22x more efficient than small batches |
| Use Batch API for images | 50% savings guaranteed |
| Group same-prompt requests | Share cache, save more |
| Submit all at once | Don't split into multiple small batches |

### DON'T âŒ

| Action | Why |
|--------|-----|
| Send <10 requests as batch | Wastes GPU initialization cost |
| Expect 90% cache on images | Only 14% actual savings |
| Send multiple small batches | One big batch is faster AND cheaper |

---

## ğŸ“ˆ Summary Table

| Finding | Details |
|---------|---------|
| **Batch API Discount** | 50% âœ… (as advertised) |
| **Big vs Small Batch** | Big is 22x more efficient! ğŸ”¥ |
| **Processing Order** | NOT FIFO - big batches first |
| **Image Cache** | Only 14% (not 90%) |
| **Best Strategy** | Batch 100+ requests together |

---

## ğŸ¯ TL;DR (Too Long; Didn't Read)

```
Want to save money? â†’ Use big batches (100+ requests)
Want to save time?  â†’ Also use big batches (they finish first!)
Working with images? â†’ Batch API is enough (cache doesn't help much)
Working with text?   â†’ Use both Batch + Cache (up to 95% savings)
```

---

*Data source: Anthropic Console + Production Batches*
*Date: 2026-01-28*
*System: GAIA Video Analysis Pipeline v4.8.3*
*By: [Washin Village](https://washinmura.jp)*
